{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HY4wzDQa7s6D",
        "0nwdv_aD6tiv",
        "7706Feaw4dMT",
        "bFlAFNM-7Tgp",
        "GZuboEb8-Fm4",
        "sTHPzFaO515x"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Databases in Movie Recommenders\n",
        "\n",
        "This notebook offers a hands-on exploration of collaborative filtering techniques and the use of vector databases in movie recommenders. It guides you through steps illustrating the concepts discussed in our blog, 'Vector Databases in Movie Recommenders.' For complete background information, refer to our post here."
      ],
      "metadata": {
        "id": "W18ybFLD_VQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n",
        "Let's begin by installing and importing all the necessary libraries. I have consolidated them in one place for clarity.\n",
        "\n"
      ],
      "metadata": {
        "id": "ckJrVWC28J9C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2lFwAyzS75Y"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install requests\n",
        "!pip install pandas\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model and dataset\n",
        "\n",
        "Next, let's load our model and dataset into our environment.\n",
        "\n",
        "The dataset contains the below files:\n",
        "\n",
        "`movie_embeddings.csv`: Contains the movies along with their embeddings and metadata.\n",
        "\n",
        "`movie2movie_encoded.json`: Contains the mappings of the original movie IDs to sequential IDs that were used for the model training.\n",
        "\n",
        "`user2user_encoded.json`: Contains the mappings of the original user IDs to sequential IDs that were used for the model training.\n",
        "\n",
        "`ratings.csv`, `movies. csv` and `links.csv`: These are the files from the original dataset from Movielens."
      ],
      "metadata": {
        "id": "yZqctNNm8e3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from Hugging Face\n",
        "from huggingface_hub import HfFolder\n",
        "from huggingface_hub import from_pretrained_keras\n",
        "model = from_pretrained_keras(\"emno/movie-recommender-collaborative-filtering\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uGgpS4CKTdDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the git repository and save it in Google Drive so we can load the files here\n",
        "embeddings_file_path = '/content/drive/My Drive/emno-movie-recommender-cf-dataset/movie_embeddings.csv'\n",
        "path_to_movie2movie_encoded = '/content/drive/My Drive/emno-movie-recommender-cf-dataset/movie2movie_encoded.json'\n",
        "path_to_user2user_encoded = '/content/drive/My Drive/emno-movie-recommender-cf-dataset/user2user_encoded.json'\n",
        "\n",
        "# Paths to the 'ratings.csv' and 'movies.csv' from the Movielens dataset files\n",
        "ratings_file_path = '/content/drive/My Drive/emno-movie-recommender-cf-dataset/ml-latest-small/ratings.csv'\n",
        "movies_file_path = '/content/drive/My Drive/emno-movie-recommender-cf-dataset/ml-latest-small/movies.csv'\n",
        "\n",
        "# Load the mappings\n",
        "with open(path_to_movie2movie_encoded, 'r') as file:\n",
        "    movie2movie_encoded = json.load(file)\n",
        "\n",
        "with open(path_to_user2user_encoded, 'r') as f:\n",
        "    user2user_encoded = json.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "eRTLnj8y2P-M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the vector database for recommendations\n",
        "\n",
        "If you haven't already, sign up for a free [emno account](https://emno.io/).\n",
        "\n",
        "Also, generate an API Key from the dashboard and copy it. We need it to work with the emno APIs. Replace the token in the scripts below with your API Key."
      ],
      "metadata": {
        "id": "57sKfrZd75M9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a collection"
      ],
      "metadata": {
        "id": "N2opdKOyOOZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://apis.emno.io/collections\"\n",
        "token = \"t_L***********\" # Replace with your API Key\n",
        "\n",
        "def check_or_create_collection(collection_name, token, dim, model):\n",
        "    headers = {\"Token\": token}\n",
        "\n",
        "    # Check for existing collection\n",
        "    response = requests.get(f\"{base_url}/{collection_name}\", headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        # Collection exists\n",
        "        return response.json()\n",
        "\n",
        "    # If collection does not exist, create a new one\n",
        "    create_payload = {\n",
        "        \"name\": collection_name,\n",
        "        \"config\": {\"dim\": dim, \"model\": model}\n",
        "    }\n",
        "    create_response = requests.post(base_url, json=create_payload, headers=headers)\n",
        "    if create_response.status_code == 201:\n",
        "        return create_response.json()\n",
        "    else:\n",
        "        raise Exception(f\"Error creating collection: {create_response.content}\")\n",
        "\n",
        "\n",
        "collection_name = \"recommender-model\"  # Replace with your collection name\n",
        "dim = 32  # Dimension of the embeddings\n",
        "model = \"CUSTOM\"\n",
        "\n",
        "collection = check_or_create_collection(collection_name, token, dim, model)\n",
        "print(f\"Collection ID: {collection['id']}\")"
      ],
      "metadata": {
        "id": "uCLm41F0TT9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert embeddings"
      ],
      "metadata": {
        "id": "TtmBKYgo8GYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100  # Adjust as needed\n",
        "collection_id = collection['id']\n",
        "headers = {\"Content-Type\": \"application/json\", \"Token\": token}\n",
        "upload_url = f\"{base_url}/{collection_id}/vectors/create\"\n",
        "\n",
        "# Function to process data into batches\n",
        "def process_data(file_path, chunk_size):\n",
        "    # Read data\n",
        "    data_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Process data into chunks\n",
        "    chunks = [data_df[i:i + chunk_size] for i in range(0, len(data_df), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "# Process data into batches\n",
        "data_batches = process_data(embeddings_file_path, batch_size)\n",
        "\n",
        "# Upload data to the collection\n",
        "for batch in tqdm(data_batches, desc=\"Uploading batches\"):\n",
        "    # Prepare payload for batch upload\n",
        "    payload = [{\n",
        "        \"content\": str(item['movieId']),\n",
        "        \"values\": json.loads(item['values']),\n",
        "        \"metadata\": item['metadata']\n",
        "    } for item in batch.to_dict(orient='records')]\n",
        "\n",
        "    # Construct the upload URL\n",
        "    upload_url = f\"{base_url}/{collection_id}/vectors/create\"\n",
        "\n",
        "    # Upload batch\n",
        "    upload_response = requests.post(upload_url, json=payload, headers=headers)\n",
        "\n",
        "    if upload_response.status_code != 200:\n",
        "        print(f\"Error uploading batch: {upload_response.content}\")\n",
        "\n",
        "print(\"\\nUpload complete.\")"
      ],
      "metadata": {
        "id": "Tph4dnDeTDFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining a method for semantic search"
      ],
      "metadata": {
        "id": "HY4wzDQa7s6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_emno(embedding):\n",
        "    url = \"https://apis.emno.io/collections/c_jeFo2rITem42TPCL/query\"\n",
        "    payload = {\n",
        "        \"vectors\": [embedding.tolist()],\n",
        "        \"limit\": 10,  # Adjust the limit as needed\n",
        "    }\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Token\": token\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    # Check the status code of the response\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error: Received status code\", response.status_code)\n",
        "        print(\"Response content:\", response.content)\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        return response.json()\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"JSON decoding failed:\", e)\n",
        "        print(\"Response content:\", response.content)\n",
        "        return None"
      ],
      "metadata": {
        "id": "5SXdGG045yUd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-based Collaborative Filtering"
      ],
      "metadata": {
        "id": "0nwdv_aD6tiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Findings results similar to a given movie"
      ],
      "metadata": {
        "id": "AmmOAvjSLhuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a Utility methods and loading"
      ],
      "metadata": {
        "id": "zSSSArgLBWd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility Function to safely extract data using regular expressions\n",
        "def safe_extract(regex, string):\n",
        "    match = re.search(regex, string)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Updated regex pattern to match titles with single quotes\n",
        "title_regex = r\"'title': '(.*?)'\"  # Non-greedy match to get the title\n",
        "\n",
        "def convert_to_json_string(metadata_str):\n",
        "    return metadata_str.replace(\"\\'\", \"\\\"\").replace('\\\"{', '{').replace('}\\\"', '}').replace('\"{', '\\'').replace('}\"', '\\'')\n",
        "\n",
        "\n",
        "# Load the movies data\n",
        "movies_df = pd.read_csv(movies_file_path)"
      ],
      "metadata": {
        "id": "TJ4WP8wPBSPR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_movie_id = 112852 # Sample movie ID. You can experiment with other IDs.\n",
        "movie_id_encoded = movie2movie_encoded.get(str(actual_movie_id))\n",
        "\n",
        "# Retrieve details for the movie\n",
        "queried_movie_details = movies_df[movies_df['movieId'] == actual_movie_id]\n",
        "\n",
        "# Display the details of the movie\n",
        "if not queried_movie_details.empty:\n",
        "    print(\"Finding movies similar to:\")\n",
        "    print(queried_movie_details.to_string(index=False))\n",
        "    print(\"\\n\")\n",
        "else:\n",
        "    print(\"Movie ID {} not found in the dataset.\".format(actual_movie_id))"
      ],
      "metadata": {
        "id": "DDsJE02y63Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Movie Embedding from the model"
      ],
      "metadata": {
        "id": "FLv3m1M27D3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a method to get embeddings for a specific movie from the model\n",
        "def get_movie_embedding(model, sequential_id):\n",
        "    sequential_id_array = np.array([sequential_id])\n",
        "    movie_embedding_layer = model.get_layer('embedding_2')\n",
        "    movie_embedding = movie_embedding_layer(sequential_id_array)\n",
        "    return movie_embedding.numpy()[0]\n",
        "\n",
        "# Get the movie embedding\n",
        "movie_embedding = get_movie_embedding(model, movie_id_encoded)"
      ],
      "metadata": {
        "id": "8SijzZatUxBf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query emno to get similar movies"
      ],
      "metadata": {
        "id": "wG4KYnZ-8zbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query emno\n",
        "movie_matching_embedding_results = query_emno(movie_embedding)\n",
        "\n",
        "\n",
        "# Parse the results\n",
        "parsed_movie_results = []\n",
        "\n",
        "for sublist in movie_matching_embedding_results:\n",
        "    for result in sublist:\n",
        "        metadata_str = result['metadata']\n",
        "        metadata_str_json = convert_to_json_string(metadata_str)\n",
        "        try:\n",
        "            metadata = json.loads(metadata_str_json)\n",
        "            movie_id = metadata.get('movie_id')\n",
        "            title = metadata.get('title')\n",
        "            genres = metadata.get('genres')\n",
        "            score = result['score']\n",
        "\n",
        "            if movie_id and title and genres:\n",
        "                parsed_movie_results.append({\n",
        "                        'movie_id': movie_id,\n",
        "                        'movies': title,\n",
        "                        'genres': genres,\n",
        "                        'scores': score\n",
        "                    })\n",
        "        except json.JSONDecodeError as e:\n",
        "#            print(f\"JSON parsing error: {e}\")\n",
        "             print(\"\")\n",
        "\n",
        "\n",
        "recommendations_for_movie_df = pd.DataFrame(parsed_movie_results)\n",
        "\n",
        "\n",
        "# Display the top recommendations\n",
        "print(\"Top Recommendations for similar movies:\")\n",
        "print(recommendations_for_movie_df.head(10).to_string(index=False))"
      ],
      "metadata": {
        "id": "2ei3VJD7MHHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding-Based Personalized Movie Recommendations"
      ],
      "metadata": {
        "id": "7706Feaw4dMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get User Embedding from the Model"
      ],
      "metadata": {
        "id": "bFlAFNM-7Tgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_embedding(model, user_id_encoded):\n",
        "    user_id_array = np.array([user_id_encoded])\n",
        "    user_embedding_layer = model.get_layer('embedding')\n",
        "    user_embedding = user_embedding_layer(user_id_array)\n",
        "    return user_embedding.numpy()[0]\n",
        "\n",
        "actual_user_id = 537 # Sample user ID. You can experiment with other IDs.\n",
        "user_id_encoded = user2user_encoded.get(str(actual_user_id))\n",
        "\n",
        "# Get the user embedding\n",
        "user_embedding = get_user_embedding(model, user_id_encoded)"
      ],
      "metadata": {
        "id": "gSwMsOBk4cln"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here are the top 10 movies based on the interaction history"
      ],
      "metadata": {
        "id": "GZuboEb8-Fm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ratings data\n",
        "ratings_df = pd.read_csv(ratings_file_path)\n",
        "\n",
        "# Filter for the specified user's ratings and sort them\n",
        "user_ratings_df = ratings_df[ratings_df['userId'] == actual_user_id]\n",
        "user_ratings_df = user_ratings_df.sort_values(by='rating', ascending=False)\n",
        "\n",
        "# Merge with the movies data to get the titles and genres\n",
        "user_ratings_with_details_df = user_ratings_df.merge(movies_df, on='movieId', how='left')\n",
        "top_10_movies = user_ratings_with_details_df.head(10)[['movieId', 'title', 'genres', 'rating']]\n",
        "\n",
        "# Display the top 10 rated movies for the user\n",
        "print(\"Top 10 movies rated by the user:\")\n",
        "print(top_10_movies.to_string(index=False))"
      ],
      "metadata": {
        "id": "jlxkE2Ld-FL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query emno to get similar movies"
      ],
      "metadata": {
        "id": "sTHPzFaO515x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query emno\n",
        "user_matching_embedding_results = query_emno(user_embedding)\n",
        "movies_watched_by_user = ratings_df[ratings_df['userId'] == actual_user_id]['movieId'].unique().tolist()\n",
        "\n",
        "\n",
        "# Parse the results and track filtered movies\n",
        "parsed_user_results = []\n",
        "filtered_movies = []  # To keep track of filtered movies\n",
        "\n",
        "for sublist in user_matching_embedding_results:\n",
        "    for result in sublist:\n",
        "        metadata_str = result['metadata']\n",
        "        metadata_str_json = convert_to_json_string(metadata_str)\n",
        "        try:\n",
        "            metadata = json.loads(metadata_str_json)\n",
        "            movie_id = metadata.get('movie_id')\n",
        "            title = metadata.get('title')\n",
        "            genres = metadata.get('genres')\n",
        "            score = result['score']\n",
        "\n",
        "            if movie_id and title and genres:\n",
        "                if int(movie_id) in movies_watched_by_user:\n",
        "                    filtered_movies.append({\n",
        "                        'movie_id': movie_id,\n",
        "                        'movies': title,\n",
        "                        'genres': genres,\n",
        "                        'scores': score\n",
        "                    })\n",
        "                else:\n",
        "                    parsed_user_results.append({\n",
        "                        'movie_id': movie_id,\n",
        "                        'movies': title,\n",
        "                        'genres': genres,\n",
        "                        'scores': score\n",
        "                    })\n",
        "        except json.JSONDecodeError as e:\n",
        "            #print(f\"JSON parsing error: {e}\")\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "recommendations_for_user_df = pd.DataFrame(parsed_user_results)\n",
        "filtered_movies_df = pd.DataFrame(filtered_movies)\n",
        "\n",
        "# Display the top 10 recommendations, excluding the movies that the user has already watched\n",
        "print(\"Top Recommendations for the user:\")\n",
        "print(recommendations_for_user_df.head(10).to_string(index=False))\n",
        "\n",
        "# Display the filtered movies\n",
        "print(\"\\nMovies filtered out (already watched by the user):\")\n",
        "print(filtered_movies_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "ZY_eWmQB5hAg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}